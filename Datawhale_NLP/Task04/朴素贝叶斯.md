# 朴素贝叶斯

## 01 使用条件概率来分类

**背景**：给定某个由x、y表示的数据点，那么该数据点来自类别c1的概率是多少？数据点来自类别c2的概率又是多少？

由**贝叶斯准则**：
$$
P(c_i|x,y) = \frac{P(c_i)\cdot P(x,y|c_i)}{P(x,y)}
$$

使用这些定义，可以定义贝叶斯分类准则为：

- 如果P(c1|x, y) > P(c2|x, y)，那么属于类别c1。
- 如果P(c1|x, y) < P(c2|x, y)，那么属于类别c2。

朴素贝叶斯分类算法可以表达为以下简要形式：
$$
P(类别|特征) = \frac{P(类别)\cdot P(特征|类别)}{P(特征)}
$$

## 02 朴素贝叶斯原理的一般形式

对应给定的样本$x$的特征向量$x_1,x_2,\cdots,x_m$,该样本$x$的类别$y$的概率可以由贝叶斯公式得到：
$$
P(y|x_1,x_2,\cdots,x_m) = \frac{P(y)P(x_1,x_2,\cdots,x_m|y)}{P(x_1,x_2,\cdots,x_m)}
$$
由**特征独立的假设**，则有：
$$
P(y|x_1,x_2,\cdots,x_m) = \frac{P(y)P(x_1,x_2,\cdots,x_m|y)}{P(x_1,x_2,\cdots,x_m)} = \frac{P(y)\prod_{i=1}^mP(x_i|y)}{P(x_1,x_2,\cdots,x_m)} 
$$
在给定样本下，$P(x_1,x_2,\cdots,x_m)$是常数，所以：
$$
P(y|x_1,x_2,\cdots,x_m) \propto P(y)\prod_{i=1}^mP(x_i|y)
$$
从而：
$$
\hat{y} = \mathop{\arg\max}_{a} P(y)\prod_{i=1}^mP(x_i|y)
$$

## 03 朴素贝叶斯算法流程

设$x=\{a_1,a_2,\cdots,a_m \}$ 为待分类项，其中$a_i$为$x$的一个特征属性。类别集合为$C=\{y_1,y_2,\cdots,y_n\}$

1. 计算每个类别概率：$P(y_1),P(y_2),\cdots,P(y_n)$
2. 对每个特征属性计算所有划分的条件概率：$P(x_{ij}|y_k)$
3. 对每个类别计算$P(y_i)\cdot P(x|y_i)$
4. 让$P(y_i)\cdot P(x|y_i)$最大的$y_i$即为$x$所属类别





### 04 使用朴素贝叶斯进行文档分类











---
**参考**：
1. 吴军著《数学之美》
2. 刘建平博客：[朴素贝叶斯算法原理小结](https://www.cnblogs.com/pinard/p/6069267.html)
3.  Peter Harrington 著，李锐 等 译 《机器学习实战》